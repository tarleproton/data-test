{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CFT_CLIP (3).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Y-ziA5r1hm"
      },
      "source": [
        "# <a name=\"1common.\"></a>\r\n",
        "## <a name=\"0.0\"></a>Содержание:\r\n",
        "* [1. Загрузка данных и библиотек](#0.)\r\n",
        "* [2. Подготовка данных](#8.)\r\n",
        "* [3. Классификация полученных изображений](#10.)\r\n",
        "* [4. CLIP](#16.)\r\n",
        "* [5. Flask Вывод запроса и изображения](#17.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR6CwHUxsFFn"
      },
      "source": [
        "## 1. Анализ данных\r\n",
        "<a name=\"0.\"></a>\r\n",
        "[<font size=\"2\">(к содержанию)</font>](#1common.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC_iEgPAc0W-",
        "outputId": "31e58b9e-fe4b-43c2-ca03-ac24677bfaf3"
      },
      "source": [
        "pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-g6nansc0\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-g6nansc0\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision~=0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 239kB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.0.0)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368688 sha256=3d60e721d60fe5a6f4daaaaa1ab4b72ac2432b11c9ae6c5415cb21831bfa25e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6swesmdp/wheels/79/51/d7/69f91d37121befe21d9c52332e04f592e17d1cabc7319b3e09\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=e91baae711d3c9c2b86e89e2d01fd892e1d8ec2e8dd30d90d75ea9a34939449a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n",
            "Successfully built clip ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, torch, torchvision, clip\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed clip-1.0 ftfy-5.9 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usvMi4rqapPF",
        "outputId": "a2d574b9-26e8-4f78-f7c0-9efc47638c43"
      },
      "source": [
        "#загрузим данные\r\n",
        "!pip install gdown==3.6.0\r\n",
        "!pip install gdown==3.6.0\r\n",
        "my_file_id = \"1V_x21M0dNb9pDUz3RbogAeau877oU4Z3\"\r\n",
        "!gdown https://drive.google.com/uc?id={my_file_id}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gdown==3.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/12/33/e9f21d0b3f85804ca570d124fb7a80c12a99948ff495cf54dfb72f18bf9e/gdown-3.6.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (1.24.3)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.6.0-cp37-none-any.whl size=5237 sha256=bf485416498bca0b4e6a962de2cf3c0bc3e5da862d269d8315542ddecf734546\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/90/fa/25654eb65da3e6da7752db71a164e0eb8f7a6fb4335eeb46ab\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed gdown-3.6.0\n",
            "Requirement already satisfied: gdown==3.6.0 in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown==3.6.0) (2020.12.5)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V_x21M0dNb9pDUz3RbogAeau877oU4Z3\n",
            "To: /content/new_f-img.zip\n",
            "63.1MB [00:00, 181MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7thL7fOC6quC",
        "outputId": "6f6071e3-685f-4ab3-d75d-706762810b89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1OuV_WQYGDW"
      },
      "source": [
        "!mkdir /content/img/\r\n",
        "!unzip -qq /content/new_f-img.zip -d /content/img/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCV2gUcp7840",
        "outputId": "7950c631-3434-4b58-b4c8-5b8837d5c6c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#загрузка модели\r\n",
        "my_file_id = \"1fKf7ciCwBWIsIjlnnpE4hy7Dl7dtipv6\"\r\n",
        "!gdown https://drive.google.com/uc?id={my_file_id}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fKf7ciCwBWIsIjlnnpE4hy7Dl7dtipv6\n",
            "To: /content/model_CFT_face\n",
            "44.8MB [00:00, 230MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw1z7RAkdI2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781ba61a-b8b2-48e3-a4a2-f82840eb0226"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eE215Tmrlq4"
      },
      "source": [
        "#библиотеки\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "from keras.preprocessing.image import load_img, img_to_array\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import cv2\r\n",
        "import re\r\n",
        "import shutil\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpt2pRsz3rM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15311328-f23d-49d7-aced-e819b1922c2e"
      },
      "source": [
        "print(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcYyLSsBzTXn"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsQXub7HCwql"
      },
      "source": [
        "#ссылка на директорию с фото\r\n",
        "IMAGES_PATH = '/content/img/new_f-img'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaUfHUPLcOoh"
      },
      "source": [
        "#загрузим модель для определения трех классов i, bro, и other\r\n",
        "model_face = torch.load('/content/drive/MyDrive/model/model_CFT_face', device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgTONFB9saR0"
      },
      "source": [
        "## 2. Подготовка данных;\r\n",
        "<a name=\"9.\"></a>\r\n",
        "[<font size=\"2\">(к содержанию)</font>](#1common.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCg6j8o9SMjM"
      },
      "source": [
        "#словарь название изображения - подпись под изображением\r\n",
        "images_labels_dict = {}\r\n",
        "\r\n",
        "for image in os.listdir(IMAGES_PATH):\r\n",
        "  image_path = os.path.join(IMAGES_PATH, image)\r\n",
        "  #clean labels from filename\r\n",
        "  image_label = image.replace(\".jpg\", '')\r\n",
        "  image_label = image_label.replace(\".JPG\", '')\r\n",
        "  image_label = image_label.replace(\".png\", '')\r\n",
        "  image_label = image_label.replace(\".PNG\", '')\r\n",
        "  image_label = image_label.split(\"_\")\r\n",
        "  images_labels_dict.update({image_path:image_label})\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVG1evZkim6W"
      },
      "source": [
        "#предсказание классов\r\n",
        "def predict(image, model):\r\n",
        "\r\n",
        "    output = model.forward(image)\r\n",
        "\r\n",
        "    output = torch.exp(output)\r\n",
        "\r\n",
        "    probs, classes = output.topk(1, dim=1)\r\n",
        "    return probs.item(), classes.item()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzfrVFoVsg2D"
      },
      "source": [
        "## 3. Классификация полученных изображений;\r\n",
        "<a name=\"10.\"></a>\r\n",
        "[<font size=\"2\">(к содержанию)</font>](#1common.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gEsQxJTbx56"
      },
      "source": [
        "#выполнение нахождения лица на фотографии с последующим его определением к одному из двух классов\r\n",
        "face_cascade_db = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\r\n",
        "!mkdir /content/img_face/\r\n",
        "\r\n",
        "def face_img(image_names, num):\r\n",
        "  !rm -rf /content/img_face/.ipynb_checkpoints\r\n",
        "  image_i = []\r\n",
        "  for i in image_names:\r\n",
        "\r\n",
        "    img = cv2.imread(i)\r\n",
        "    img_name = i\r\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "    faces = face_cascade_db.\\\r\n",
        "        detectMultiScale(img, 1.1, 19)        \r\n",
        "    for (x,y,w,h) in faces:\r\n",
        "        roi_color = img[y-30:y+60+h, x-60:x+60+w]\r\n",
        "        cv2.imwrite(r'/content/img_face/{}.jpg'.format(x), roi_color)\r\n",
        "        IMAGES_PATH_2 = '/content/img_face/'\r\n",
        "        name_image = []\r\n",
        "        for image in os.listdir(IMAGES_PATH_2):\r\n",
        "          name_image.append(os.path.join(IMAGES_PATH_2,image))\r\n",
        "          \r\n",
        "        photos = [Image.open(photo_file) for photo_file in name_image] \r\n",
        "        photos_preprocessed = [preprocess(photo) for photo in photos]\r\n",
        "        for i in photos_preprocessed:\r\n",
        "          img_top = i[np.newaxis,:].to(device)         \r\n",
        "          top_prob, top_class = predict(img_top, model_face)\r\n",
        "          if num == 0:\r\n",
        "            if top_class == 0:\r\n",
        "              image_i.append(img_name)\r\n",
        "          if num == 1:\r\n",
        "            if top_class == 1:\r\n",
        "              image_i.append(img_name)\r\n",
        "  #очистим папку\r\n",
        "  for filename in os.listdir('/content/img_face/'):\r\n",
        "    os.unlink('/content/img_face/' + filename)\r\n",
        "  return image_i"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U5fPsIUtAia"
      },
      "source": [
        "## 4. CLIP\r\n",
        "<a name=\"16.\"></a>\r\n",
        "[<font size=\"2\">(к содержанию)</font>](#1common.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLBJnb6dNuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9847c3-7d36-4b06-da22-44e715410c04"
      },
      "source": [
        "#CLIP\r\n",
        "import clip\r\n",
        "import torch\r\n",
        "!mkdir static\r\n",
        "\r\n",
        "\r\n",
        "# Load the model\r\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "model, preprocess = clip.load('ViT-B/32', device)\r\n",
        "\r\n",
        "\r\n",
        "# Prepare the inputs\r\n",
        "#аргументы - текстовый запрос и количество желаемых фотографий\r\n",
        "\r\n",
        "def find_picture(inputs, numbrr):\r\n",
        "  #чистим папку static\r\n",
        "  for filename in os.listdir('/content/static/'):\r\n",
        "    os.unlink('/content/static/' + filename)\r\n",
        "\r\n",
        "  name_image = []\r\n",
        "\r\n",
        "  for image in os.listdir(IMAGES_PATH):\r\n",
        "    name_image.append(os.path.join(IMAGES_PATH,image))\r\n",
        "\r\n",
        "  photos = [Image.open(photo_file) for photo_file in name_image]\r\n",
        "      \r\n",
        "  photos_preprocessed = torch.stack([preprocess(photo) for photo in photos]).to(device)\r\n",
        "\r\n",
        "  user_input = inputs\r\n",
        "  find_my = 0\r\n",
        "  #условие для запуска поиска по лицу i или bro\r\n",
        "  if re.search(r'\\bi\\b', user_input):\r\n",
        "    find_my += 1\r\n",
        "  if re.search(r'\\bbro\\b', user_input):\r\n",
        "    find_my -= 2\r\n",
        "\r\n",
        "\r\n",
        "  user_input = user_input.replace(\"i\", 'man')\r\n",
        "  #print('='*60)\r\n",
        "  text_inputs = clip.tokenize(user_input).to(device)\r\n",
        "\r\n",
        "  # Calculate features\r\n",
        "  with torch.no_grad():\r\n",
        "      image_features = model.encode_image(photos_preprocessed)\r\n",
        "      text_features = model.encode_text(text_inputs)\r\n",
        "\r\n",
        "  # Pick the top 5 most similar labels for the image\r\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\r\n",
        "  text_features /= text_features.norm(dim=-1, keepdim=True)\r\n",
        "  similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\r\n",
        "  values, indices = similarity[0].topk(numbrr)\r\n",
        "\r\n",
        "\r\n",
        "  IMAGE_FOLDER = []\r\n",
        "\r\n",
        "  \r\n",
        "  #поиcк i или bro по условию\r\n",
        "  if find_my > 0:\r\n",
        "    IMAGE_FOLDER = []\r\n",
        "    for value, index in zip(values, indices):\r\n",
        "      IMAGE_FOLDER.append(name_image[index])\r\n",
        "\r\n",
        "    IMAGE_FOLDER = face_img(IMAGE_FOLDER, 0)\r\n",
        " \r\n",
        "\r\n",
        "  if find_my < 0:\r\n",
        "    IMAGE_FOLDER = []\r\n",
        "    for value, index in zip(values, indices):\r\n",
        "      IMAGE_FOLDER.append(name_image[index])\r\n",
        "\r\n",
        "    IMAGE_FOLDER = face_img(IMAGE_FOLDER, 1)\r\n",
        "\r\n",
        "    \r\n",
        "  #вывод по названию фото\r\n",
        "  else:\r\n",
        "    for image, label in images_labels_dict.items():\r\n",
        "          if user_input in label:\r\n",
        "            #print(f\"All pictures with {user_input}\")\r\n",
        "            image = Image.open(image)\r\n",
        "            IMAGE_FOLDER.append(name_image[index])\r\n",
        "            #plt.imshow(image)\r\n",
        "            #plt.show()\r\n",
        "    print('='*60)\r\n",
        "\r\n",
        "\r\n",
        "    # Print the result\r\n",
        "    #print(\"\\nTop predictions for %s:\\n\"%(user_input))\r\n",
        "    for value, index in zip(values, indices):\r\n",
        "        #print(f\"{name_image[index]:>16s}: {100 * value.item():.2f}%\")\r\n",
        "        image = Image.open(name_image[index])\r\n",
        "        IMAGE_FOLDER.append(name_image[index])\r\n",
        "        #plt.imshow(image)\r\n",
        "        #plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  #вывод для Flask в папку static\r\n",
        "  for i in IMAGE_FOLDER:\r\n",
        "\r\n",
        "    dst = '/content/static/'\r\n",
        "    shutil.copy(i, dst)\r\n",
        "\r\n",
        " \r\n",
        "  IMAGES_PATH_filt = '/content/static'\r\n",
        "\r\n",
        "  name_image_filt = []\r\n",
        "\r\n",
        "\r\n",
        "  for image in os.listdir(IMAGES_PATH_filt):\r\n",
        "    name_image_filt.append(image)\r\n",
        "\r\n",
        "  return name_image_filt"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 354M/354M [00:02<00:00, 170MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEOIQDsBm-uS"
      },
      "source": [
        "#!rm -rf /content/img_face/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql5zzo0etN_4"
      },
      "source": [
        "## 5. Flask Вывод запроса и изображения\r\n",
        "<a name=\"17.\"></a>\r\n",
        "[<font size=\"2\">(к содержанию)</font>](#1common.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySeegMhJ1B6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a72bbc-3d51-451c-c977-1a4e44f29e67"
      },
      "source": [
        "# installation\r\n",
        "!pip install flask==0.12.2\r\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/32/e3597cb19ffffe724ad4bf0beca4153419918e7fa4ba6a34b04ee4da3371/Flask-0.12.2-py2.py3-none-any.whl (83kB)\n",
            "\r\u001b[K     |████                            | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (1.1.1)\n",
            "Installing collected packages: flask\n",
            "  Found existing installation: Flask 1.1.2\n",
            "    Uninstalling Flask-1.1.2:\n",
            "      Successfully uninstalled Flask-1.1.2\n",
            "Successfully installed flask-0.12.2\n",
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN8Bg2ox70Oa"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\r\n",
        "from flask import Flask, render_template, session, request, redirect "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DARlEA051ICI",
        "outputId": "b32393e4-fafb-43cf-b6b7-a4a60e4a61b8"
      },
      "source": [
        "\r\n",
        "!mkdir templates\r\n",
        "%cd /content/templates\r\n",
        "\r\n",
        "html = \"\"\"\r\n",
        " <!DOCTYPE html>\r\n",
        "<html>\r\n",
        "<head>\r\n",
        "    <title> Page </title>\r\n",
        "    <meta http-equiv=\"Content-type\" content=\"text/html\">\r\n",
        "</head>\r\n",
        "<body>\r\n",
        "    <form action=\"{{ url_for(\"page_start\") }}\" method=\"post\">\r\n",
        "        <p><b>Hello!</b><br>\r\n",
        "        <p><b>Please enter a word to search: </b><br>\r\n",
        "        <input name = \"search_word\" type = 'text' autofocus placeholder = \"here\">\r\n",
        "\t<p><b>How many pictures? </b><br>\r\n",
        "\t<input name = \"pictures_amount\" type=\"number\" autofocus placeholder = \"here\" size=\"2\" min=\"1\" max=\"99\" value=\"1\">\r\n",
        "        <p> <input type = \"submit\" value = \"Send\"> </p>\r\n",
        "</form>\r\n",
        "</body>\r\n",
        "</html>\"\"\"\r\n",
        "\r\n",
        "with open(\"index.html\",\"a+\") as f:\r\n",
        "  f.write(html)\r\n",
        "\r\n",
        "html_pred = \"\"\"\r\n",
        "<!DOCTYPE html>\r\n",
        "<html>\r\n",
        "<head>\r\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n",
        "    <title>Page_start</title>\r\n",
        "<style>\r\n",
        "* {\r\n",
        "  box-sizing: border-box;\r\n",
        "}\r\n",
        "\r\n",
        "body {\r\n",
        "  margin: 0;\r\n",
        "  font-family: Arial, Helvetica, sans-serif;\r\n",
        "}\r\n",
        "\r\n",
        ".header {\r\n",
        "  text-align: center;\r\n",
        "  padding: 32px;\r\n",
        "}\r\n",
        "\r\n",
        ".row {\r\n",
        "  display: -ms-flexbox; /* IE 10 */\r\n",
        "  display: flex;\r\n",
        "  -ms-flex-wrap: wrap; /* IE 10 */\r\n",
        "  flex-wrap: wrap;\r\n",
        "  padding: 0 4px;\r\n",
        "}\r\n",
        "\r\n",
        "/* Create two equal columns that sits next to each other */\r\n",
        ".column {\r\n",
        "  -ms-flex: 50%; /* IE 10 */\r\n",
        "  flex: 50%;\r\n",
        "  padding: 0 4px;\r\n",
        "}\r\n",
        "\r\n",
        ".column img {\r\n",
        "  margin-top: 8px;\r\n",
        "  vertical-align: middle;\r\n",
        "}\r\n",
        "\r\n",
        "/* Style the button */\r\n",
        ".btn {\r\n",
        "  border: none;\r\n",
        "  outline: none;\r\n",
        "  padding: 10px 16px;\r\n",
        "  background-color: #f1f1f1;\r\n",
        "  cursor: pointer;\r\n",
        "  font-size: 18px;\r\n",
        "}\r\n",
        "\r\n",
        ".btn:hover {\r\n",
        "  background-color: #ddd;\r\n",
        "}\r\n",
        "\r\n",
        ".btn.active {\r\n",
        "  background-color: #666;\r\n",
        "  color: white;\r\n",
        "}\r\n",
        "</style>\r\n",
        "</head>\r\n",
        "<body>\r\n",
        "    <div class=\"row\"> \r\n",
        "        <div class=\"column\">\r\n",
        "    {% for name in images %}\r\n",
        "    <img src=\"{{url_for('static', filename=name)}}\" style=\"width:20%\" />\r\n",
        "  {% endfor %}\r\n",
        "  </div>\r\n",
        "</div>\r\n",
        "\r\n",
        "</body>\r\n",
        "</html>\"\"\"\r\n",
        "\r\n",
        "with open(\"page_start.html\",\"a+\") as f1:\r\n",
        "  f1.write(html_pred)\r\n",
        "\r\n",
        "%cd /content"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/templates\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHjYoeO-2Loh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94001914-a698-4e46-8ce0-597afb0734a3"
      },
      "source": [
        "#Fkask\r\n",
        "template_dir = os.path.abspath('/content/templates')\r\n",
        "app = Flask(__name__, template_folder = template_dir) \r\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\r\n",
        "\r\n",
        "@app.route('/', methods=['POST', 'GET'])\r\n",
        "def home():\r\n",
        "    return render_template('index.html')\r\n",
        "\r\n",
        "@app.route(\"/page_start\", methods = ['POST'])\r\n",
        "def page_start():\r\n",
        "    input = request.form['search_word']\r\n",
        "    number = int(request.form['pictures_amount'])\r\n",
        "    images = find_picture(input, number)\r\n",
        "\r\n",
        "    return render_template('page_start.html', images = images)\r\n",
        "    \r\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://84eb01649e16.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Cf-2gZhSUX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}